pip install pandas numpy scikit-learn transformers torch spacy
python -m spacy download en_core_web_sm
import pandas as pd

# Load your review data (assuming CSV format)
df = pd.read_csv('reviews.csv')  # Replace with your filename

# Basic preprocessing
df['review_text'] = df['review_text'].fillna('').astype(str)
from transformers import pipeline

# Initialize sentiment analysis pipeline
sentiment_pipeline = pipeline("sentiment-analysis", model="distilbert-base-uncased-finetuned-sst-2-english")

# Apply sentiment analysis
def get_sentiment(review):
    result = sentiment_pipeline(review)[0]
    label = result['label']
    score = result['score']
    return label, score

# Apply to reviews
df[['sentiment_label', 'sentiment_score']] = df['review_text'].apply(lambda x: pd.Series(get_sentiment(x)))

# For aggregate purposes, convert labels to numerical
label_mapping = {'POSITIVE': 1, 'NEGATIVE': 0}
df['sentiment_numeric'] = df['sentiment_label'].map(label_mapping)
# Assuming columns: 'bank_name', 'rating' (e.g., 1-5)
# Aggregate mean sentiment scores per bank and rating
sentiment_summary = df.groupby(['bank_name', 'rating']).agg(
    mean_sentiment_score=('sentiment_score', 'mean'),
    review_count=('review_text', 'count')
).reset_index()

# Save or display
sentiment_summary.to_csv('sentiment_aggregation.csv', index=False)
from sklearn.feature_extraction.text import TfidfVectorizer

# Preprocessing function
import spacy
nlp = spacy.load('en_core_web_sm')

def preprocess_text(text):
    doc = nlp(text.lower())
    tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]
    return ' '.join(tokens)

df['processed_text'] = df['review_text'].apply(preprocess_text)

# For each bank, get top keywords
banks = df['bank_name'].unique()

# Store themes per bank
bank_themes = {}

for bank in banks:
    bank_reviews = df[df['bank_name'] == bank]['processed_text']
    # TF-IDF vectorizer
    vectorizer = TfidfVectorizer(max_features=50)
    tfidf_matrix = vectorizer.fit_transform(bank_reviews)
    feature_names = vectorizer.get_feature_names_out()
    # Sum scores to get overall importance
    scores = tfidf_matrix.toarray().sum(axis=0)
    keyword_scores = list(zip(feature_names, scores))
    # Sort keywords
    sorted_keywords = sorted(keyword_scores, key=lambda x: x[1], reverse=True)
    print(f"\nTop keywords for {bank}:")
    for kw, score in sorted_keywords[:10]:
        print(f"{kw}: {score:.2f}")
    # Save for potential theme grouping
    bank_themes[bank] = [kw for kw, score in sorted_keywords[:10]]
